### TCP连接的数据包

###### TCP连接详解

​		HTTP 要传送一条报文时，会**以流的形式**将报文数据的内容通过一条打开的TCP 连接**按序传输**。TCP 收到数据流之后，会将数据流砍成被称作段的小数据块，并将段封装在IP 分组中，通过因特网进行传输。

###### TCP连接的数据传输

~~~txt
1. 浏览器从URL 中解析出服务器的主机名；
2. 浏览器将服务器的主机名转换成服务器的IP 地址；
3. 浏览器将端口号（如果有的话）从URL 中解析出来；
4. 浏览器建立一条与Web 服务器的TCP 连接；
5. 浏览器向服务器发送一条HTTP 请求报文；
6. 服务器向浏览器回送一条HTTP 响应报文
7. 关闭连接，浏览器显示文档。
~~~



​	![image-20201104195515096](C:\Users\申杰\AppData\Roaming\Typora\typora-user-images\image-20201104195515096.png)

![image-20201104195521831](C:\Users\申杰\AppData\Roaming\Typora\typora-user-images\image-20201104195521831.png)

一个包1400字节，那么一次性发送大量数据，就必须分成多个包。比如，一个 10MB 的文件，需要发送7100多个包。

**发送的时候，TCP 协议为每个包编号**（sequence number，简称 SEQ），以便接收的一方按照顺序还原。万一**发生丢包，也可以知道丢失的是哪一个包**。

**第一个包的编号是一个随机数**。为了便于理解，这里就把它称为1号包。假定这个包的负载长度是100字节，那么**可以推算出下一个包的编号应该是101(编号加长度)**。这就是说，每个数据包都可以得到两个编号：**自身的编号，以及下一个包的编号**。接收方由此知道，应该**按照什么顺序将它们还原成原始文件**。

### TCP连接的性能分析

​		HTTP 事务的时延有以下几种主要原因。

1. **客户端需要根据域名来分析IP和端口号**,如果目标网站属于小众网站且使用解析服务很差,那么**这个DNS查询会消耗不少时间**
2. 接下来，客户端会向服务器发送一条TCP 连接请求，并等待服务器回送一个请求接受应答。**每条新的TCP 连接都会有连接建立时延**。这个值通常最多只有一两秒钟，但如果有数百个HTTP 事务的话，这个值会快速地叠加上去。
3. 一旦连接建立起来了，客户端就会通过新建立的TCP 管道来发送HTTP 请求。数据到达时，Web 服务器会从TCP 连接中读取请求报文，并对请求进行处理。因特网**传输请求报文，以及服务器处理请求报文都需要时间**。
4. 然后，**Web 服务器会回送HTTP 响应，这也需要花费时间**。
   这些TCP 网络时延的大小取决于硬件速度、网络和服务器的负载，请求和响应报文的尺寸，以及客户端和服务器之间的距离。TCP 协议的技术复杂性也会对时延产生巨大的影响。

###### TCP连接的延迟和延迟确认

​		**TCP连接的延迟**: 通常HTTP 事务都不会交换太多数据，此时，SYN/SYN+ACK 握手会产生一个可测量的时延.小的HTTP 事务可能会在TCP 建立上花费50%，或更多的时间

​	由于因特网自身无法确保可靠的分组传输（因特网路由器超负荷的话，可以随意丢弃分组），所以TCP 实现了自己的确认机制来确保数据的成功传输。

​		每个TCP 段都有一个序列号和数据完整性校验和。每**个段的接收者收到完好的段时，都会向发送者回送小的确认分组**。如果发送者没有在指定的窗口时间内收到确认信息，发送者就认为分组已被破坏或损毁，并重发数据。**为了保证减少不必要的检查和错误的检测结果**,TCP**会使用一个延迟确认算法**, 会将一个确认信息在一个窗口时间(一般是100~200ms)外再进行发送

###### HTTP事务的慢启动

​		TCP 数据传输的性能还取决于**TCP 连接的使用期**（age）。TCP 连接**会随着时间进行自我“调谐”**，**起初会限制连接的最大速度**，如果数据成功传输，**会随着时间的推移提高传输的速度**。这种调谐被称为TCP **慢启动**（slow start），用于防止因特网的突然过载和拥塞。

###### TCP连接的串行事务处理时延

​		**如果只对连接进行简单的管理，TCP 的性能时延可能会叠加起来**
比如，假设有一个包含了3 个嵌入图片的Web 页面。浏览器需要发起4 个HTTP 事务来显示此页面：1 个用于顶层的HTML 页面，3 个用于嵌入的图片。**如果每个事务都需要（串行地建立）一条新的连接，那么连接时延和慢启动时延就会叠加起来**

###### TCP连接的并行连接

​		HTTP **允许客户端打开多条连接**，并行地执行多个HTTP 事务。

​		包含嵌入对象的组合页面(比如多个iframe或是内部多个外联文件等), 如果能（通过并行连接）克服单条连接的空载时间和带宽限制，加载速度也会有所提高。**时延可以重叠起来**，而且如果单条连接没有充分利用客户端的因特网带宽，可以将未用带宽分配来装载其他对象。

​		**并行连接不一定更快,但是一般上看去会感觉快一些**（看带宽）

###### TCP连接的持久连接

​		**Web 客户端经常会打开到同一个站点的连接**。比如，一个Web 页面上的大部分内嵌图片通常都来自同一个Web 站点，而且相当一部分指向其他对象的**超链通常都指向同一个站点**。因此，初始化了对某服务器HTTP 请求的应用程序很可能会在不久的将来对那台服务器发起更多的请求（比如，获取在线图片）。**这种性质被称为站点局部性（site locality）**。

​		**因此**，HTTP/1.1（以及HTTP/1.0 的各种增强版本） 允许HTTP 设备在事务处理结束之后**将TCP 连接保持在打开状态**，以便为未来的HTTP 请求重用现存的连接。**在事务处理结束之后仍然保持在打开状态的TCP 连接被称为持久连接**。非持久连接会在每个事务结束之后关闭。持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为止。

​	重用已对目标服务器打开的空闲持久连接，就**可以避开缓慢的连接建立阶段**。而且，**已经打开的连接还可以避免慢启动**的拥塞适应阶段，以便更快速地进行数据的传输。

###### TCP连接的持久连接和并行连接的缺陷

​		并行连接可以提高复合页面的传输速度。但并行连接也有一些缺点。

1. 每个事务都会打开 / 关闭一条**新的连接，会耗费时间和带**宽

2. 由于 TCP 慢启动特性的存在，每条**新连接的性能都会有所降低**

3. 可打开的**并行连接数量实际上是有限的**。

   **持久连接有一些比并行连接更好的地方**。

   1. 持久连接**降低了时延和连接建立的开销**，**将连接保持在已调谐状态**，

   2. 而且**减少了打开连接的潜在数量**。

   3. 但是，管理持久连接时**要特别小心**，**不然**就**会累积出大量的空闲连接**，耗费本地以及远程客户端和服务器上的资源。

      **持久连接与并行连接配合使用可能是最高效的方式**。现在，很多Web 应用程序都会打开少量的并行连接，其中的每一个都是持久连接

###### TCP连接的持久连接的实现方式

持久连接有两种类型：

  1. 比较老的HTTP/1.0+的“keep-alive”连接

  2. 现代的HTTP/1.1“persistent”连接。

     ​	实现HTTP/1.0 keep-alive 连接的客户端可以**通过包含Connection: Keep-Alive首部请求将一条连接保持在打开状态**

     ​	如果服务器愿意为下一条请求将连接保持在打开状态，就在响应中包含相同的首部。如果响应中没有Connection: Keep-Alive 首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。

HTTP/1.1 **逐渐停止了对keep-alive 连接的支持**，用一种名为持久连接（**persistent-connection）的改进型设计取代了它**。持久连接的目的与keep-alive 连接的目的相同，但工作机制更优一些。

​		**与HTTP/1.0+ 的keep-alive 连接不同，HTTP/1.1 持久连接在默认情况下是激活**. 除非特别指明，否则HTTP/1.1 假定所有连接都是持久的。要在事务处理结束之后将连接关闭，HTTP/1.1 应用程序必须向报文中显式地添加一个Connection:close 首部。

​		这**是与以前的HTTP 协议版本很重要的区别**，在以前的版本中，keepalive连接要么是可选的，要么根本就不支持。

###### TCP连接的管道连接

​		管**道化连接: 在响应到达之前，可以将多条请求放入队列**。当第一条请求通过网络流向地球另一端的服务器时，第二条和第三条请求也可以开始发送了。在高时延网络条件下，**这样做可以降低网络的环回时间，提高性能**。

### TCP连接的关闭

​		**TCP 连接是双向的**。**TCP 连接的每一端都有一个输入队列和一个输出队列**，用于数据的读或写。放入一端输出队列中的数据最终会出现在另一端的输入队列中。

​		应用程序可以关闭TCP 输入和输出信道中的任意一个，或者将两者都关闭了。**套接字调用close() 会将TCP 连接的输入和输出信道都关闭了**。这被称作“完全关闭” 。还可以用**套接字调用shutdown() 单独关闭输入或输出信道**。这被称为“半关闭”
关闭连接的输出信道总是很安全的,关闭连接的输入信道比较危险，除非你知道另一端不打算再发送其他数据了

### 服务器概念简介

实际的Web服务器会做些什么?

	1. 建立连接——接受一个客户端连接，或者如果不希望与这个客户端建立连接，就将其关闭。
 	2. 接收请求——从网络中读取一条HTTP 请求报文。
 	3. 处理请求——对请求报文进行解释，并采取行动。
 	4. 访问资源——访问报文中指定的资源。
 	5. 构建响应——创建带有正确首部的HTTP 响应报文。
 	6. 发送响应——将响应回送给客户端。
 	7. 记录事务处理过程——将与已完成事务有关的内容记录在一个日志文件中。

###### 服务器代理的概念

​		Web 代理（proxy）服务器是网络的中间实体。**代理位于客户端和服务器之间，扮演“中间人”的角色**，在各端点之间来回传送HTTP 报文

​		简单来说：

   1. 正向代理,隐藏真实客户端

   2. 反向代理,隐藏真实服务器

      反向代理：

      ​		假扮Web 服务器被称为替代物（surrogate）或反向代理（reverse proxy）的代理接收发给Web 服务器的真实请求，但与Web 服务器不同的是，它们可以发起与其他服务器的通信，以便按需定位所请求的内容。

###### 服务器缓存的概念

​		有很多客户端访问一个流行的原始服务器页面时，服务器会多次传输同一份文档，每次传送给一个客户端。一些相同的字节会在网络中一遍遍地传输。这些冗余的数据传输会耗尽昂贵的网络带宽，降低传输速度，加重Web 服务器的负载。**有了缓存，就可以保留第一条服务器响应的副本，后继请求就可以由缓存的副本来应对了**，这样可以减少那些流入/ 流出原始服务器的、被浪费掉了的重复流量。

​		缓存(缓存不仅仅是本机自身的缓存, 还有缓存服务器一说)可以解决的常见问题:

	1. 带宽瓶颈
 	2. 瞬间拥塞
 	3. 距离时延(超远距离访问, 比如:中国访问美国的网站, 需要计算光速)

**可以用已有的副本为某些到达缓存的请求提供服务**。这**被称为缓存命中**（cache hit），其他一些到达缓存的请求可能会由**于没有副本可用**，而被转发给原始服务器。这被称为**缓存未命中**（cache miss）